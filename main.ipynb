{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms, datasets, models\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to dataset: /scratch/g/plaviole/srubenstein/DeepLearning/bigger_dataset\n",
    "import random\n",
    "from PIL import Image\n",
    "# import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "data_path = Path(\"/scratch/g/plaviole/srubenstein/DeepLearning/bigger_dataset\")\n",
    "\n",
    "# 1. Get all image paths\n",
    "image_path_list = list(data_path.glob(\"*/*/*.tiff\"))\n",
    "\n",
    "# 2. Pick a random image path\n",
    "random_image_path = random.choice(image_path_list)\n",
    "\n",
    "# 3. Get image class from path name\n",
    "image_class = random_image_path.parent.stem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# write a transform for image\n",
    "data_transform = transforms.Compose([\n",
    "    # resize to be half as large\n",
    "    transforms.Resize(250),\n",
    "    transforms.RandomCrop(240),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    # crop to resnet input size\n",
    "    transforms.CenterCrop(224),\n",
    "    # Flip images randomly on the horizontal\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    # Turn the image into a torch.Tensor\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dir = data_path / \"train\"\n",
    "test_dir = data_path / \"test\"\n",
    "\n",
    "train_data = datasets.ImageFolder(root=train_dir, transform=data_transform, target_transform=None)\n",
    "test_data = datasets.ImageFolder(root=test_dir, transform=data_transform)\n",
    "\n",
    "# get class names as a list\n",
    "class_names = train_data.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put data in DataLoaders and get model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet101\n",
    "import torch\n",
    "model = resnet101(weights='DEFAULT')\n",
    "model.to(device)\n",
    "train_dataloader = DataLoader(dataset=train_data, batch_size=1, num_workers=0, shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=test_data, batch_size=1, num_workers=0, shuffle=True)\n",
    "if(next(model.parameters()).is_cuda):   \n",
    "    print(\"Model on GPU\")\n",
    "else:\n",
    "    print(\"Model on CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define loss function, optimizer, and scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch import nn\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model.parameters(), lr=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.2, patience=6, min_lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to calculate accuraacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy (a classification metric)\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    \"\"\"Calculates accuracy between truth labels and predictions.\n",
    "\n",
    "    Args:\n",
    "        y_true (torch.Tensor): Truth labels for predictions.\n",
    "        y_pred (torch.Tensor): Predictions to be compared to predictions.\n",
    "\n",
    "    Returns:\n",
    "        [torch.float]: Accuracy value between y_true and y_pred, e.g. 78.45\n",
    "    \"\"\"\n",
    "\n",
    "    # for testing:\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for printing train time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "def print_train_time(start: float,\n",
    "                     end: float,\n",
    "                     device: torch.device = None):\n",
    "  \"\"\"Prints difference between start and end time.\"\"\"\n",
    "  total_time = end-start\n",
    "  print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
    "  return total_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_time_start_on_cpu = timer()\n",
    "epochs = 20\n",
    "\n",
    "# 2. Create empty results dictionary\n",
    "results = {\"train_loss\": [],\n",
    "            \"train_acc\": [],\n",
    "            \"test_loss\": [],\n",
    "            \"test_acc\": []}\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch: {epoch}\\n----\")\n",
    "\n",
    "    # train \n",
    "    train_loss, train_acc = 0, 0\n",
    "\n",
    "    # loop through dataloader\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        model.train()\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # forward pass\n",
    "        y_pred = model(X)\n",
    "        # calculate loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss\n",
    "        train_acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n",
    "        # optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "        # loss backward\n",
    "        loss.backward()\n",
    "        # optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "        # print what's happening\n",
    "        if(batch % 100 == 0):\n",
    "            print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)}\")\n",
    "\n",
    "    # Divide total train loss by length of train dataloader\n",
    "    train_loss /= len(train_dataloader)\n",
    "    train_acc /= len(train_dataloader)\n",
    "\n",
    "    # testing \n",
    "    test_loss, test_acc = 0, 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        for X_test, y_test in test_dataloader:\n",
    "            X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "            # forward pass\n",
    "            test_pred = model(X_test)\n",
    "            # calculate the loss\n",
    "            test_loss += loss_fn(test_pred, y_test)\n",
    "            # calculate the accuracy\n",
    "            test_acc += accuracy_fn(y_true=y_test, y_pred=test_pred.argmax(dim=1))\n",
    "            \n",
    "        # calculate the test loss average per batch\n",
    "        test_loss /= len(test_dataloader)\n",
    "        test_acc /= len(test_dataloader)\n",
    "\n",
    "    scheduler.step(test_loss)\n",
    "\n",
    "    print(f\"\\nTrain loss: {train_loss:.4f} | Train acc: {train_acc:.4f} | Test loss: {test_loss:.4f} | Test acc: {test_acc:.4f}\")\n",
    "\n",
    "    # update results dictionary\n",
    "    results[\"train_loss\"].append(train_loss)\n",
    "    results[\"train_acc\"].append(train_acc)\n",
    "    results[\"test_loss\"].append(test_loss)\n",
    "    results[\"test_acc\"].append(test_acc)\n",
    "\n",
    "    # Calculate training time\n",
    "    train_time_end_on_cpu = timer()\n",
    "    total_trian_time_model_0 = print_train_time(start=train_time_start_on_cpu,\n",
    "                                            end=train_time_end_on_cpu,\n",
    "                                            device=str(next(model.parameters()).device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install matplotlib \n",
    "import sys\n",
    "print(sys.executable)\n",
    "# !{sys.executable} -m pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to calculate loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_loss_curves(results: dict[str, list[float]]):\n",
    "  \"\"\"Plots training curves of a results dictionary.\"\"\"\n",
    "  # Get the loss values of the results dictionary(training and test)\n",
    "  loss = torch.tensor(results[\"train_loss\"]).cpu()\n",
    "  loss = [torch.detach(tensor) for tensor in loss]\n",
    "  test_loss = torch.tensor(results[\"test_loss\"]).cpu()\n",
    "\n",
    "  # Get the accuracy values of the results dictionary (training and test)\n",
    "  accuracy = results[\"train_acc\"]\n",
    "  test_accuracy = results[\"test_acc\"]\n",
    "\n",
    "  # Figure out how mnay epochs there were\n",
    "  epochs = range(len(results[\"train_loss\"]))\n",
    "\n",
    "  # Setup a plot\n",
    "  plt.figure(figsize=(15, 7))\n",
    "\n",
    "  # Plot the loss\n",
    "  plt.subplot(1, 2, 1)\n",
    "  print(f\"type of epochs: {type(epochs)} | type of loss: {type(loss)}\")\n",
    "  plt.plot(epochs, loss, label=\"train_loss\")\n",
    "  plt.plot(epochs, test_loss, label=\"test_loss\")\n",
    "  plt.title(\"Loss\")\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.legend() \n",
    "\n",
    "  # Plot the accuracy\n",
    "  plt.subplot(1, 2, 2)\n",
    "  plt.plot(epochs, accuracy, label=\"train_accuracy\")\n",
    "  plt.plot(epochs, test_accuracy, label=\"test_accuracy\")\n",
    "  plt.title(\"Accuracy\")\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
